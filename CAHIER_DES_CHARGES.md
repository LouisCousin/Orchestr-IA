# Orchestr'IA â€” Cahier des Charges Technique Complet

> **Version** : 6.0
> **Date** : 26 fÃ©vrier 2026
> **Auteur** : Ã‰quipe Orchestr'IA
> **Statut** : Document de rÃ©fÃ©rence

---

## Table des matiÃ¨res

1. [Vision du projet](#1-vision-du-projet)
2. [Architecture globale](#2-architecture-globale)
3. [Phase 1 â€” Pipeline fondamental](#3-phase-1--pipeline-fondamental) âœ…
4. [Phase 2 â€” Multi-fournisseurs et RAG de base](#4-phase-2--multi-fournisseurs-et-rag-de-base) âœ…
5. [Phase 2.5 â€” RAG avancÃ© et garde-fous](#5-phase-25--rag-avancÃ©-et-garde-fous) âœ…
6. [Phase 3 â€” Intelligence du pipeline](#6-phase-3--intelligence-du-pipeline) âœ…
7. [Phase 4 â€” Performance et optimisation](#7-phase-4--performance-et-optimisation) âœ…
8. [Phase 5 â€” IntÃ©gration Gemini 3.1 et Context Caching](#8-phase-5--intÃ©gration-gemini-31-et-context-caching) ğŸ”§
9. [Phase 6 â€” Acquisition GitHub (Clone de dÃ©pÃ´ts)](#9-phase-6--acquisition-github-clone-de-dÃ©pÃ´ts) ğŸ”§
10. [Phase 7 â€” Orchestration multi-agents](#10-phase-7--orchestration-multi-agents) ğŸ“‹
11. [Matrice des dÃ©pendances](#11-matrice-des-dÃ©pendances)
12. [Stack technique](#12-stack-technique)
13. [Annexes](#13-annexes)

**LÃ©gende** : âœ… ImplÃ©mentÃ© | ğŸ”§ En cours | ğŸ“‹ PlanifiÃ©

---

## 1. Vision du projet

**Orchestr'IA** est un pipeline intelligent de gÃ©nÃ©ration documentaire assistÃ©e par IA. Il transforme un corpus de documents sources (PDF, DOCX, TXT, HTML, Excel, dÃ©pÃ´ts GitHub) en documents professionnels structurÃ©s via un processus en 5 Ã©tapes : Configuration â†’ Acquisition â†’ Plan â†’ GÃ©nÃ©ration â†’ Export.

### 1.1 Principes directeurs

| Principe | Description |
|---|---|
| **FiabilitÃ© factuelle** | ZÃ©ro hallucination : chaque affirmation est sourcÃ©e ou marquÃ©e `{{NEEDS_SOURCE}}` |
| **Human-in-the-Loop** | Checkpoints de validation humaine Ã  chaque Ã©tape critique |
| **Multi-fournisseurs** | Support OpenAI, Anthropic et Google Gemini avec fallback automatique |
| **Optimisation des coÃ»ts** | Context caching, batch processing, modÃ¨les Ã©conomiques pour les tÃ¢ches secondaires |
| **ScalabilitÃ©** | Corpus de 500k+ chunks, documents de 100+ pages, traitement asynchrone |

### 1.2 Cas d'usage cibles

- Rapports d'analyse (20-80 pages) Ã  partir de corpus documentaire
- Documents de formation Ã  partir de supports techniques
- SynthÃ¨ses de veille Ã  partir d'articles et Ã©tudes
- Propositions de services Ã  partir de spÃ©cifications client
- Documentation technique Ã  partir de dÃ©pÃ´ts de code source

---

## 2. Architecture globale

### 2.1 Structure des modules

```
src/
â”œâ”€â”€ app.py                          # Point d'entrÃ©e Streamlit
â”œâ”€â”€ core/                           # 30 modules â€” Moteur du pipeline
â”‚   â”œâ”€â”€ orchestrator.py             # Chef d'orchestre + ProjectState
â”‚   â”œâ”€â”€ prompt_engine.py            # GÃ©nÃ©ration dynamique de prompts
â”‚   â”œâ”€â”€ rag_engine.py               # Pipeline RAG hybride (ChromaDB)
â”‚   â”œâ”€â”€ semantic_chunker.py         # Chunking sÃ©mantique hiÃ©rarchique
â”‚   â”œâ”€â”€ local_embedder.py           # Embeddings locaux (multilingual-e5-large)
â”‚   â”œâ”€â”€ reranker.py                 # Cross-encoder reranking
â”‚   â”œâ”€â”€ text_extractor.py           # Extraction multi-format (Docling/PyMuPDF)
â”‚   â”œâ”€â”€ corpus_extractor.py         # Structuration corpus + TF-IDF
â”‚   â”œâ”€â”€ corpus_acquirer.py          # Acquisition asynchrone (fichiers + URLs)
â”‚   â”œâ”€â”€ corpus_deduplicator.py      # DÃ©doublonnage par hash
â”‚   â”œâ”€â”€ plan_parser.py              # Parsing et normalisation de plans
â”‚   â”œâ”€â”€ plan_corpus_linker.py       # PrÃ©-analyse planâ†”corpus
â”‚   â”œâ”€â”€ conditional_generator.py    # GÃ©nÃ©ration conditionnelle par couverture
â”‚   â”œâ”€â”€ quality_evaluator.py        # Ã‰valuation qualitÃ© (6 critÃ¨res)
â”‚   â”œâ”€â”€ factcheck_engine.py         # VÃ©rification factuelle
â”‚   â”œâ”€â”€ feedback_engine.py          # Apprentissage des corrections humaines
â”‚   â”œâ”€â”€ glossary_engine.py          # Gestion terminologique
â”‚   â”œâ”€â”€ citation_engine.py          # Citations APA 7e Ã©dition
â”‚   â”œâ”€â”€ persona_engine.py           # ModÃ©lisation persona/audience
â”‚   â”œâ”€â”€ export_engine.py            # Export DOCX avec styling
â”‚   â”œâ”€â”€ cost_tracker.py             # Suivi des coÃ»ts API
â”‚   â”œâ”€â”€ checkpoint_manager.py       # Checkpoints HITL
â”‚   â”œâ”€â”€ metadata_store.py           # SQLite (documents + chunks)
â”‚   â”œâ”€â”€ profile_manager.py          # Profils de projet prÃ©-configurÃ©s
â”‚   â”œâ”€â”€ template_library.py         # BibliothÃ¨que de templates
â”‚   â”œâ”€â”€ hitl_journal.py             # Journal des dÃ©cisions HITL
â”‚   â”œâ”€â”€ persistent_instructions.py  # Instructions persistantes hiÃ©rarchiques
â”‚   â”œâ”€â”€ metadata_overrides.py       # Corrections manuelles de mÃ©tadonnÃ©es
â”‚   â””â”€â”€ grobid_client.py            # Extraction bibliographique (Docker)
â”œâ”€â”€ pages/                          # 8 pages Streamlit
â”‚   â”œâ”€â”€ page_accueil.py             # Accueil et gestion de projets
â”‚   â”œâ”€â”€ page_configuration.py       # Configuration fournisseur IA
â”‚   â”œâ”€â”€ page_acquisition.py         # Upload/URL/GitHub acquisition
â”‚   â”œâ”€â”€ page_plan.py                # Import/gÃ©nÃ©ration/Ã©dition du plan
â”‚   â”œâ”€â”€ page_generation.py          # GÃ©nÃ©ration avec barre de progression
â”‚   â”œâ”€â”€ page_export.py              # Export DOCX et tÃ©lÃ©chargement
â”‚   â”œâ”€â”€ page_dashboard.py           # MÃ©triques et logs en temps rÃ©el
â”‚   â””â”€â”€ page_bibliotheque.py        # Gestion et recherche dans le corpus
â”œâ”€â”€ providers/                      # 4 fournisseurs IA
â”‚   â”œâ”€â”€ base.py                     # Interface abstraite + types Batch
â”‚   â”œâ”€â”€ openai_provider.py          # GPT-4.1/4o/3.5 + Batch API
â”‚   â”œâ”€â”€ anthropic_provider.py       # Claude Opus/Sonnet/Haiku + Batch
â”‚   â””â”€â”€ gemini_provider.py          # Gemini 3.1 Pro/Flash + Context Cache
â””â”€â”€ utils/                          # 7 modules utilitaires
    â”œâ”€â”€ config.py                   # Chargement YAML + pricing
    â”œâ”€â”€ file_utils.py               # I/O fichiers + JSON
    â”œâ”€â”€ logger.py                   # ActivityLog structurÃ©
    â”œâ”€â”€ token_counter.py            # Comptage tokens (tiktoken)
    â”œâ”€â”€ providers_registry.py       # Registre dynamique de providers
    â””â”€â”€ content_validator.py        # Validation anti-bot pour scraping
```

### 2.2 Flux de donnÃ©es principal

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACQUISITION â”‚â”€â”€â”€â–¶â”‚   PLAN      â”‚â”€â”€â”€â–¶â”‚ GÃ‰NÃ‰RATION  â”‚â”€â”€â”€â–¶â”‚  Ã‰VALUATION â”‚â”€â”€â”€â–¶â”‚   EXPORT    â”‚
â”‚             â”‚    â”‚             â”‚    â”‚             â”‚    â”‚             â”‚    â”‚             â”‚
â”‚ â€¢ Fichiers  â”‚    â”‚ â€¢ Import    â”‚    â”‚ â€¢ RAG searchâ”‚    â”‚ â€¢ QualitÃ©   â”‚    â”‚ â€¢ DOCX      â”‚
â”‚ â€¢ URLs      â”‚    â”‚ â€¢ Auto-gen  â”‚    â”‚ â€¢ Prompt    â”‚    â”‚ â€¢ Factcheck â”‚    â”‚ â€¢ Styling   â”‚
â”‚ â€¢ GitHub    â”‚    â”‚ â€¢ Ã‰dition   â”‚    â”‚ â€¢ LLM call  â”‚    â”‚ â€¢ Feedback  â”‚    â”‚ â€¢ Branding  â”‚
â”‚ â€¢ Extractionâ”‚    â”‚ â€¢ Linking   â”‚    â”‚ â€¢ Multi-passâ”‚    â”‚ â€¢ HITL      â”‚    â”‚ â€¢ Download  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                     â”‚                 â”‚
       â–¼                                     â–¼                 â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ChromaDB â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Providers â”‚    â”‚Cost Trackerâ”‚
  â”‚ + SQLiteâ”‚                         â”‚ (3 APIs)  â”‚    â”‚            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 ModÃ¨le de donnÃ©es (ProjectState)

```python
@dataclass
class ProjectState:
    name: str
    user_id: str = "user_default"
    plan: Optional[NormalizedPlan] = None
    corpus: Optional[StructuredCorpus] = None
    generated_sections: dict = {}          # section_id â†’ contenu
    section_summaries: list[str] = []      # RÃ©sumÃ©s pour contexte inter-sections
    quality_reports: dict = {}             # section_id â†’ QualityReport
    factcheck_reports: dict = {}           # section_id â†’ FactcheckReport
    citations: dict = {}                   # section_id â†’ liste de citations
    glossary: dict = {}                    # terme â†’ dÃ©finition
    personas: dict = {}                    # persona_id â†’ PersonaConfig
    feedback_history: list = []            # Historique des corrections humaines
    cost_report: dict = {}                 # Rapport de coÃ»ts cumulÃ©s
    current_step: str = "init"             # initâ†’planâ†’corpusâ†’generationâ†’reviewâ†’exportâ†’done
    generation_config: dict = {}           # ParamÃ¨tres de gÃ©nÃ©ration actifs
    cache_id: Optional[str] = None         # ID du cache Gemini actif (Phase 5)
```

### 2.4 Persistance par projet

```
projects/{project_id}/
â”œâ”€â”€ state.json           # ProjectState sÃ©rialisÃ©
â”œâ”€â”€ corpus/              # Documents sources (001_doc.pdf, ...)
â”œâ”€â”€ chromadb/            # Base vectorielle (HNSW + SQLite)
â”œâ”€â”€ metadata.db          # MÃ©tadonnÃ©es documents + chunks (SQLite)
â””â”€â”€ cache/               # Cache d'extraction (hash MD5 â†’ JSON)
```

---

## 3. Phase 1 â€” Pipeline fondamental âœ…

> **Statut** : ImplÃ©mentÃ© et opÃ©rationnel
> **Objectif** : Pipeline de base fonctionnel de bout en bout

### 3.1 Modules implÃ©mentÃ©s

| Module | Fichier | FonctionnalitÃ©s |
|---|---|---|
| **Orchestrateur** | `orchestrator.py` | Pipeline sÃ©quentiel, gestion d'Ã©tat, sauvegarde JSON |
| **Prompt Engine** | `prompt_engine.py` | Templates systÃ¨me/section/raffinement/rÃ©sumÃ©/plan |
| **Plan Parser** | `plan_parser.py` | Parsing numÃ©rotÃ© (1. / 1.1 / 1.1.1), normalisation hiÃ©rarchique |
| **Corpus Extractor** | `corpus_extractor.py` | Structuration, extraction mots-clÃ©s TF-IDF, digest multi-paliers |
| **Text Extractor** | `text_extractor.py` | ChaÃ®ne de fallback : Docling â†’ PyMuPDF â†’ pdfplumber â†’ PyPDF2 |
| **Export Engine** | `export_engine.py` | DOCX avec styles (titres, corps, marges, logo, couleurs) |
| **Cost Tracker** | `cost_tracker.py` | Estimation prÃ©-gÃ©nÃ©ration, suivi temps rÃ©el, rapport cumulÃ© |
| **Config** | `config/default.yaml` | 204 paramÃ¨tres configurables |

### 3.2 Interface utilisateur (Streamlit)

8 pages fonctionnelles :
- **Accueil** : CrÃ©ation/chargement de projets
- **Configuration** : SÃ©lection provider/modÃ¨le, paramÃ¨tres de gÃ©nÃ©ration
- **Acquisition** : Upload multi-fichier, saisie d'URLs
- **Plan** : Import texte/markdown, gÃ©nÃ©ration auto, Ã©dition inline
- **GÃ©nÃ©ration** : Lancement section par section avec barre de progression
- **Export** : GÃ©nÃ©ration DOCX, personnalisation charte, tÃ©lÃ©chargement
- **Dashboard** : MÃ©triques temps rÃ©el, logs d'activitÃ©, graphiques
- **BibliothÃ¨que** : Recherche sÃ©mantique dans le corpus indexÃ©

### 3.3 Profils prÃ©-configurÃ©s

5 profils YAML dans `profiles/default/` :

| Profil | Cible | Pages | Ton |
|---|---|---|---|
| `rapport_analyse.yaml` | Rapport d'analyse | ~20 | Professionnel, analytique |
| `document_formation.yaml` | Support de formation | ~15 | PÃ©dagogique |
| `synthese_veille.yaml` | SynthÃ¨se de veille | ~10 | Informatif, concis |
| `proposition_services.yaml` | Proposition commerciale | ~12 | Persuasif |
| `compte_rendu.yaml` | Compte-rendu de rÃ©union | ~5 | Factuel, structurÃ© |

---

## 4. Phase 2 â€” Multi-fournisseurs et RAG de base âœ…

> **Statut** : ImplÃ©mentÃ© et opÃ©rationnel
> **Objectif** : Support multi-providers avec recherche vectorielle

### 4.1 Fournisseurs IA

#### 4.1.1 Architecture Provider

```python
# Interface commune (base.py)
class BaseProvider(ABC):
    def generate(prompt, system_prompt, model, temperature, max_tokens) â†’ AIResponse
    def is_available() â†’ bool
    def get_default_model() â†’ str
    def list_models() â†’ list[str]
    # Batch (optionnel)
    def supports_batch() â†’ bool
    def submit_batch(requests) â†’ batch_id
    def poll_batch(batch_id) â†’ BatchStatus
    def retrieve_batch_results(batch_id) â†’ dict[custom_id, content]
```

#### 4.1.2 Providers implÃ©mentÃ©s

| Provider | ModÃ¨les | Batch | Retry |
|---|---|---|---|
| **OpenAI** | GPT-4.1, GPT-4.1-mini, GPT-4.1-nano, GPT-4o, GPT-4o-mini, GPT-4-turbo, GPT-3.5-turbo | âœ… Batch API | âœ… Exponentiel |
| **Anthropic** | Claude Opus 4.6, Sonnet 4.5, Haiku 3.5 | âœ… Messages Batch | âœ… Exponentiel |
| **Google Gemini** | Gemini 3.0 Pro, 3.0 Flash (â†’ **3.1 Pro/Flash en Phase 5**) | âŒ Non | âœ… Exponentiel |

#### 4.1.3 Pricing actuel (`model_pricing.yaml`)

| Provider | ModÃ¨le | Input $/1M | Output $/1M | Contexte |
|---|---|---|---|---|
| OpenAI | gpt-4.1 | $2.00 | $8.00 | 1M |
| OpenAI | gpt-4.1-mini | $0.40 | $1.60 | 1M |
| OpenAI | gpt-4.1-nano | $0.10 | $0.40 | 1M |
| OpenAI | gpt-4o | $2.50 | $10.00 | 128K |
| Anthropic | claude-opus-4-6 | $15.00 | $75.00 | 200K |
| Anthropic | claude-sonnet-4-5 | $3.00 | $15.00 | 200K |
| Anthropic | claude-haiku-3-5 | $0.80 | $4.00 | 200K |
| Google | gemini-3.0-pro | $1.25 | $10.00 | 1M |
| Google | gemini-3.0-flash | $0.10 | $0.40 | 1M |

### 4.2 RAG de base

- Vectorisation via ChromaDB (stockage HNSW + cosine distance)
- Recherche top-k avec seuil de pertinence configurable
- GÃ©nÃ©ration conditionnelle selon la couverture du corpus
- Mode batch pour OpenAI et Anthropic avec fallback temps rÃ©el

---

## 5. Phase 2.5 â€” RAG avancÃ© et garde-fous âœ…

> **Statut** : ImplÃ©mentÃ© et opÃ©rationnel
> **Objectif** : Pipeline RAG hybride de qualitÃ© production

### 5.1 Pipeline RAG en 5 Ã©tapes

```
Document â†’ Extraction â†’ Chunking sÃ©mantique â†’ Embeddings â†’ ChromaDB â†’ Reranking â†’ Prompt
            (Docling)    (hierarchique)        (local)      (HNSW)     (cross-enc.)
```

#### 5.1.1 Extraction PDF avancÃ©e

- **Moteur primaire** : Docling 2.0+ (extraction structurÃ©e avec tables, figures)
- **Fallback chain** : Docling â†’ PyMuPDF â†’ pdfplumber â†’ PyPDF2
- **Batch Docling** : Traitement par lots de 30 pages pour les gros documents (>50 pages)
- **Coverage check** : Seuil de 80% des pages couvertes avant rattrapage PyMuPDF

#### 5.1.2 Chunking sÃ©mantique

```yaml
# Configuration (default.yaml)
rag.chunking:
  strategy: "semantic"      # "semantic" | "fixed"
  max_chunk_tokens: 800
  min_chunk_tokens: 100
  overlap_sentences: 2
```

Le `SemanticChunker` :
- DÃ©tecte les frontiÃ¨res de section (titres, sauts de paragraphe)
- Respecte la hiÃ©rarchie du document source
- Produit des chunks cohÃ©rents de 100-800 tokens avec overlap de 2 phrases

#### 5.1.3 Embeddings locaux

- **ModÃ¨le** : `intfloat/multilingual-e5-large` via FastEmbed (ONNX quantisÃ©)
- **Performance** : ~300 Mo RAM, pas de GPU requis
- **Batch** : Vectorisation de masse (batch_size=512)
- **Fallback** : Embeddings ChromaDB natifs si FastEmbed indisponible
- **Providers alternatifs** : OpenAI `text-embedding-3-small` ou Gemini (via config)

#### 5.1.4 Reranking cross-encoder

- **ModÃ¨le** : `cross-encoder/ms-marco-MiniLM-L-12-v2`
- **Flow** : ChromaDB retourne 20 candidats â†’ reranker sÃ©lectionne les top 10
- **DÃ©sactivable** : `rag.reranking_enabled: false`

### 5.2 Anti-hallucination

Bloc injectÃ© systÃ©matiquement dans chaque prompt de gÃ©nÃ©ration :

```
â•â•â• RÃˆGLES DE FIABILITÃ‰ (NON NÃ‰GOCIABLES) â•â•â•
1. SOURCES EXCLUSIVES : seuls les blocs corpus fournis sont autorisÃ©s
2. MARQUEUR D'INSUFFISANCE : {{NEEDS_SOURCE: [description]}} pour les lacunes
3. ATTRIBUTION : citation par rÃ©fÃ©rence APA ou nom de fichier
4. TRANSPARENCE : section plus courte plutÃ´t qu'information inventÃ©e
â•â•â• FIN DES RÃˆGLES â•â•â•
```

- DÃ©tection des marqueurs `{{NEEDS_SOURCE}}` rÃ©siduels avant export DOCX
- Alerte utilisateur si des points non sourcÃ©s subsistent

### 5.3 Liaison plan-corpus

Le `PlanCorpusLinker` effectue une prÃ©-analyse avant la gÃ©nÃ©ration :
- Analyse thÃ©matique du corpus (jusqu'Ã  30 documents)
- Extraction des 3 premiers chunks par document
- Mapping planâ†”corpus pour estimer la couverture par section

### 5.4 MÃ©tadonnÃ©es SQLite

Deux tables dans `metadata.db` :

```sql
-- Table documents
CREATE TABLE documents (
    doc_id TEXT PRIMARY KEY,
    filepath TEXT, title TEXT, authors TEXT,
    year INTEGER, language TEXT, doc_type TEXT,
    hash TEXT, extraction_method TEXT, apa_reference TEXT
);

-- Table chunks
CREATE TABLE chunks (
    doc_id TEXT, chunk_id TEXT PRIMARY KEY,
    text TEXT, page_number INTEGER,
    section_title TEXT, token_count INTEGER,
    language TEXT, doc_type TEXT
);
```

---

## 6. Phase 3 â€” Intelligence du pipeline âœ…

> **Statut** : ImplÃ©mentÃ© et opÃ©rationnel
> **Objectif** : Ã‰valuation qualitÃ©, vÃ©rification factuelle, apprentissage

### 6.1 Ã‰valuation qualitÃ© (`quality_evaluator.py`)

6 critÃ¨res pondÃ©rÃ©s, Ã©valuÃ©s par le LLM aprÃ¨s chaque section :

| CritÃ¨re | Poids | Description |
|---|---|---|
| ConformitÃ© au plan | 1.0 | Respect du titre, niveau et consignes |
| Couverture corpus | 1.5 | Utilisation effective des sources |
| CohÃ©rence narrative | 0.8 | FluiditÃ© et enchaÃ®nement avec les sections prÃ©cÃ©dentes |
| Taille cible | 0.5 | Respect du budget de pages |
| FiabilitÃ© factuelle | 1.5 | Absence d'hallucinations |
| TraÃ§abilitÃ© sources | 1.2 | Attribution correcte des citations |

- **Seuil auto-raffinement** : score global < 3.0/5.0 â†’ raffinement automatique
- **ModÃ¨le d'Ã©valuation** : le plus Ã©conomique disponible (configurable)

### 6.2 VÃ©rification factuelle (`factcheck_engine.py`)

- Extraction automatique des affirmations factuelles (max 30/section)
- VÃ©rification croisÃ©e avec le corpus source
- Score de fiabilitÃ© par affirmation (%)
- **Seuil auto-correction** : score < 80% â†’ correction automatique
- Rapport dÃ©taillÃ© avec les affirmations non vÃ©rifiÃ©es

### 6.3 Boucle de feedback (`feedback_engine.py`)

- Analyse des corrections humaines (diff Levenshtein, seuil > 15%)
- Extraction des patterns de correction (style, terminologie, structure)
- Injection dans les prompts des sections suivantes
- Apprentissage cumulatif au fil du projet

### 6.4 Modules optionnels (dÃ©sactivÃ©s par dÃ©faut)

| Module | Fichier | Description |
|---|---|---|
| **Glossaire** | `glossary_engine.py` | Extraction et harmonisation terminologique, injection dans les prompts |
| **Citations APA** | `citation_engine.py` | RÃ©fÃ©rences APA 7e Ã©dition, bibliographie automatique |
| **Personas** | `persona_engine.py` | ModÃ©lisation de l'audience cible, adaptation du ton |
| **GROBID** | `grobid_client.py` | Extraction bibliographique via Docker (articles scientifiques) |

---

## 7. Phase 4 â€” Performance et optimisation âœ…

> **Statut** : ImplÃ©mentÃ© et opÃ©rationnel
> **Objectif** : ScalabilitÃ© et rapiditÃ© de traitement

### 7.1 Acquisition asynchrone (`corpus_acquirer.py`)

- TÃ©lÃ©chargement parallÃ¨le via `aiohttp` + `aiofiles`
- Throttling configurable (1s entre les requÃªtes)
- User-agent rotation, timeout adaptatif (mode normal/lent)
- Validation anti-bot (`content_validator.py`)

### 7.2 Extraction parallÃ¨le (`text_extractor.py`)

- `ProcessPoolExecutor` avec scaling dynamique basÃ© sur `psutil`
- Nombre de workers adaptÃ© Ã  la RAM/CPU disponibles
- Cache d'extraction MD5 : pas de re-processing des fichiers dÃ©jÃ  vus

### 7.3 Pipeline de gÃ©nÃ©ration asynchrone (`orchestrator.py`)

- `ThreadPoolExecutor` : l'Ã©valuation post-gÃ©nÃ©ration de la section N tourne en parallÃ¨le avec la gÃ©nÃ©ration de la section N+1
- Verrou (`Lock`) pour protÃ©ger `save_state` et les mutations d'Ã©tat
- Sauvegarde incrÃ©mentale aprÃ¨s chaque section

### 7.4 Pipeline d'embedding asynchrone (`rag_engine.py`)

- **Phase 4.2** : Les embeddings du lot N+1 sont calculÃ©s pendant l'Ã©criture ChromaDB du lot N
- Batch size configurable (dÃ©faut: 512)
- **Phase 5 (sÃ©curitÃ© mÃ©moire)** : Segmentation en lots de 10 000 chunks max pour Ã©viter les OOM

### 7.5 Cache LRU RAG

- Cache en mÃ©moire pour `search_for_section` (Ã©vite les recherches redondantes)
- Invalidation automatique Ã  chaque `index_corpus()` ou `reset()`
- Thread-safe via `threading.Lock`

---

## 8. Phase 5 â€” IntÃ©gration Gemini 3.1 et Context Caching ğŸ”§

> **Statut** : Ã€ implÃ©menter
> **Objectif** : Exploiter Gemini 3.1 Pro comme "cerveau" principal avec context caching pour rÃ©duire les coÃ»ts de 90%
> **PrioritÃ©** : Haute

### 8.1 Contexte et motivations

**ProblÃ¨me actuel** : Le provider Gemini utilise les modÃ¨les `gemini-3.0-pro` et `gemini-3.0-flash`, qui sont **dÃ©prÃ©ciÃ©s** (shutdown le 9 mars 2026). De plus, le module d'embeddings Gemini dans `rag_engine.py` utilise l'ancien SDK `google.generativeai` (obsolÃ¨te depuis novembre 2025).

**OpportunitÃ©** : Gemini 3.1 Pro offre une fenÃªtre de contexte de 1M tokens Ã  $2/1M input, avec context caching Ã  **$0.20/1M** (rÃ©duction de 90%). Pour un corpus typique de 200K tokens rÃ©utilisÃ© sur 20 sections, cela reprÃ©sente une Ã©conomie de ~$7.20 par document.

### 8.2 Mise Ã  jour du provider Gemini

#### 8.2.1 ModÃ¨les cibles

| ModÃ¨le | Model ID | Usage | Input $/1M | Output $/1M |
|---|---|---|---|---|
| **Gemini 3.1 Pro** | `gemini-3.1-pro-preview` | Cerveau principal (raisonnement, gÃ©nÃ©ration) | $2.00 | $12.00 |
| **Gemini 3.1 Pro Custom Tools** | `gemini-3.1-pro-preview-customtools` | Workflows agentic multi-outils | $2.00 | $12.00 |
| **Gemini 3 Flash** | `gemini-3-flash-preview` | TÃ¢ches secondaires (rÃ©sumÃ©s, Ã©valuation) | $0.50 | $3.00 |

**Tokens cachÃ©s** :
- Gemini 3.1 Pro : $0.20/1M (90% de rÃ©duction sur l'input)
- Gemini 3 Flash : $0.05/1M (90% de rÃ©duction sur l'input)
- Stockage cache : ~$0.50/h/1M tokens (Pro) â€” ~$1.00/h/1M tokens (Flash)

#### 8.2.2 Modifications de `gemini_provider.py`

```python
class GeminiProvider(BaseProvider):
    """Fournisseur Google Gemini 3.1."""

    MODELS = [
        "gemini-3.1-pro-preview",
        "gemini-3.1-pro-preview-customtools",
        "gemini-3-flash-preview",
    ]

    def get_default_model(self) -> str:
        return "gemini-3-flash-preview"

    def generate(self, prompt, system_prompt=None, model=None,
                 temperature=0.7, max_tokens=4096,
                 cached_content=None, thinking_level=None) -> AIResponse:
        """GÃ©nÃ¨re avec support du context caching et du thinking level."""
        ...
```

**ParamÃ¨tres ajoutÃ©s** :
- `cached_content: Optional[str]` â€” Nom du cache Ã  utiliser
- `thinking_level: Optional[str]` â€” `"minimal"`, `"low"`, `"medium"`, `"high"` (dÃ©faut: `"high"`)
- `max_output_tokens` â€” Doit Ãªtre explicitement dÃ©fini (dÃ©faut API = 8 192, max = 65 536)

#### 8.2.3 SystÃ¨me de pensÃ©e Ã  3 niveaux

Gemini 3.1 Pro introduit un paramÃ¨tre `thinking_level` qui module la profondeur de raisonnement :

| Niveau | Usage recommandÃ© | Latence |
|---|---|---|
| `minimal` | RÃ©sumÃ©s simples, extraction de mÃ©tadonnÃ©es | ~2s |
| `low` | Reformulation, nettoyage de texte | ~5s |
| `medium` | GÃ©nÃ©ration de contenu standard | ~15s |
| `high` | Analyse complexe, raisonnement long, factcheck | ~36s |

**Mapping par tÃ¢che Orchestr'IA** :

| TÃ¢che | thinking_level |
|---|---|
| RÃ©sumÃ© de section | `low` |
| GÃ©nÃ©ration de plan | `medium` |
| GÃ©nÃ©ration de section | `high` |
| Raffinement multi-pass | `high` |
| Ã‰valuation qualitÃ© | `medium` |
| VÃ©rification factuelle | `high` |
| Feedback analysis | `low` |

### 8.3 Context Caching

#### 8.3.1 Principe

Le context caching permet de stocker le corpus une seule fois cÃ´tÃ© Google et de le rÃ©utiliser pour chaque appel de gÃ©nÃ©ration. Le coÃ»t de lecture des tokens cachÃ©s est rÃ©duit de 90%.

```
Sans cache :  20 sections Ã— 200K tokens input = 4M tokens Ã— $2.00/1M = $8.00
Avec cache :  1 cache Ã— 200K tokens + 20 lectures Ã— $0.20/1M = $0.04 + stockage
Ã‰conomie :    ~$7.56 (~95%)
```

#### 8.3.2 API cible (SDK `google-genai`)

```python
from google import genai
from google.genai import types

client = genai.Client(api_key=API_KEY)

# 1. CrÃ©er le cache (une seule fois aprÃ¨s indexation du corpus)
cache = client.caches.create(
    model='models/gemini-3.1-pro-preview',
    config=types.CreateCachedContentConfig(
        display_name=f'orchestria-{project_id}',
        system_instruction=system_prompt,      # Inclus dans le cache
        contents=[corpus_xml_content],          # Corpus complet en XML
        ttl='7200s',                            # 2 heures
    )
)

# 2. Utiliser le cache pour chaque section
response = client.models.generate_content(
    model='models/gemini-3.1-pro-preview',
    contents=section_prompt,                    # Seul le prompt section varie
    config=types.GenerateContentConfig(
        cached_content=cache.name,
        temperature=0.7,
        max_output_tokens=4096,
        # PAS de system_instruction ici (dÃ©jÃ  dans le cache)
        # PAS de tools ici (incompatible avec cached_content)
    )
)

# 3. Mettre Ã  jour le TTL si nÃ©cessaire
client.caches.update(
    name=cache.name,
    config=types.UpdateCachedContentConfig(ttl='3600s')
)
```

#### 8.3.3 Contraintes techniques

| Contrainte | Impact | Mitigation |
|---|---|---|
| `system_instruction` doit Ãªtre dans le cache | Le prompt systÃ¨me ne peut pas varier entre sections | Construire un system prompt gÃ©nÃ©rique incluant anti-hallucination et persona |
| Pas de `tools` avec `cached_content` | Incompatible avec le mode agentic | Utiliser le mode agentic sans cache, ou dÃ©sactiver les tools pour la gÃ©nÃ©ration documentaire |
| Contenu immutable aprÃ¨s crÃ©ation | Pas de modification du corpus cachÃ© | RecrÃ©er un nouveau cache si le corpus change |
| Minimum 2 048 tokens pour le cache | Les petits corpus ne bÃ©nÃ©ficient pas du caching | Fallback en mode standard si corpus < 2 048 tokens |
| Caching implicite instable sur 3.x | Ne pas compter sur le cache automatique | Toujours utiliser le caching explicite |

#### 8.3.4 StratÃ©gie de caching

```
corpus_tokens < 2048     â†’ Mode standard (pas de cache)
2048 â‰¤ corpus_tokens < 200K â†’ Cache explicite, TTL = 2h, thinking_level adaptatif
corpus_tokens â‰¥ 200K     â†’ Cache explicite, TTL = 2h, ATTENTION repricing long-context
```

**PiÃ¨ge du repricing** : Au-delÃ  de 200K tokens en input, Google facture TOUT le request (y compris l'output) au tarif long-context ($4/1M input au lieu de $2, $18/1M output au lieu de $12). Le cost_tracker doit en tenir compte.

#### 8.3.5 Nouveau module : `gemini_cache_manager.py`

```python
class GeminiCacheManager:
    """GÃ¨re le cycle de vie des caches Gemini pour un projet."""

    def create_corpus_cache(
        self, project_id: str, corpus_xml: str,
        system_prompt: str, model: str, ttl: int = 7200
    ) -> str:
        """CrÃ©e un cache contenant le corpus et le system prompt."""

    def get_or_create_cache(self, project_id: str, ...) -> str:
        """RÃ©cupÃ¨re le cache existant ou en crÃ©e un nouveau."""

    def extend_cache_ttl(self, cache_name: str, ttl: int) -> None:
        """Prolonge le TTL d'un cache existant."""

    def delete_cache(self, cache_name: str) -> None:
        """Supprime un cache explicitement."""

    def estimate_cache_cost(
        self, corpus_tokens: int, num_sections: int, ttl_hours: float
    ) -> dict:
        """Estime le coÃ»t avec vs sans cache."""

    def should_use_cache(self, corpus_tokens: int, num_sections: int) -> bool:
        """DÃ©termine si le caching est rentable pour ce projet."""
```

### 8.4 Mise Ã  jour des embeddings Gemini

Dans `rag_engine.py`, la mÃ©thode `_get_embeddings_gemini()` utilise l'ancien SDK :

```python
# AVANT (obsolÃ¨te)
import google.generativeai as genai
result = genai.embed_content(model=..., content=batch, task_type="retrieval_document")

# APRÃˆS (nouveau SDK)
from google import genai
client = genai.Client(api_key=API_KEY)
result = client.models.embed_content(
    model='models/text-embedding-004',
    contents=batch,
    config=types.EmbedContentConfig(task_type='RETRIEVAL_DOCUMENT')
)
```

### 8.5 Mise Ã  jour du pricing

Ajouter dans `model_pricing.yaml` :

```yaml
google:
  gemini-3.1-pro-preview:
    input: 2.00
    input_cached: 0.20          # Nouveau
    input_long_context: 4.00    # >200K tokens â€” Nouveau
    output: 12.00
    output_long_context: 18.00  # >200K tokens â€” Nouveau
    cache_storage_per_hour: 0.50  # Nouveau
    context_window: 1000000
    max_output_tokens: 65536    # Nouveau
  gemini-3.1-pro-preview-customtools:
    input: 2.00
    input_cached: 0.20
    output: 12.00
    context_window: 1000000
    max_output_tokens: 65536
  gemini-3-flash-preview:
    input: 0.50
    input_cached: 0.05          # Nouveau
    output: 3.00
    cache_storage_per_hour: 1.00  # Nouveau
    context_window: 1000000
    max_output_tokens: 65536
```

### 8.6 Mise Ã  jour du cost_tracker

Le `CostTracker` doit supporter :
- Le calcul des tokens cachÃ©s vs non-cachÃ©s
- Le repricing long-context (>200K tokens)
- L'estimation du coÃ»t de stockage du cache
- Le seuil de rentabilitÃ© du cache (break-even ~4 requÃªtes/heure pour 1M tokens)

### 8.7 Livrables Phase 5

| # | Livrable | Fichier(s) |
|---|---|---|
| 5.1 | Mise Ã  jour provider Gemini 3.1 | `providers/gemini_provider.py` |
| 5.2 | Module de gestion du cache | `core/gemini_cache_manager.py` (nouveau) |
| 5.3 | Migration embeddings Gemini | `core/rag_engine.py` |
| 5.4 | Mise Ã  jour pricing | `config/model_pricing.yaml` |
| 5.5 | Mise Ã  jour cost tracker | `core/cost_tracker.py` |
| 5.6 | IntÃ©gration thinking_level | `core/orchestrator.py`, `providers/gemini_provider.py` |
| 5.7 | UI config caching | `pages/page_configuration.py` |
| 5.8 | Tests unitaires | `tests/unit/test_gemini_provider.py`, `tests/unit/test_gemini_cache.py` |
| 5.9 | Tests d'intÃ©gration | `tests/integration/test_gemini_caching_pipeline.py` |

---

## 9. Phase 6 â€” Acquisition GitHub (Clone de dÃ©pÃ´ts) ğŸ”§

> **Statut** : Ã€ implÃ©menter
> **Objectif** : Permettre l'acquisition de dÃ©pÃ´ts GitHub comme source de corpus pour la gÃ©nÃ©ration de documentation technique
> **PrioritÃ©** : Haute

### 9.1 Contexte et motivations

L'acquisition actuelle supporte les fichiers locaux (upload) et les URLs (scraping). Pour les projets de documentation technique, les dÃ©veloppeurs ont besoin d'intÃ©grer directement le code source et la documentation existante d'un dÃ©pÃ´t GitHub.

**Cas d'usage** :
- GÃ©nÃ©rer une documentation technique Ã  partir du code source
- CrÃ©er un guide d'architecture Ã  partir de la structure d'un dÃ©pÃ´t
- Produire un rapport d'audit de code
- RÃ©sumer les README, CHANGELOG et issues d'un projet

### 9.2 FonctionnalitÃ©s

#### 9.2.1 Clone et filtrage

```python
class GitHubAcquirer:
    """Acquisition de dÃ©pÃ´ts GitHub comme corpus."""

    def clone_repo(
        self,
        repo_url: str,               # https://github.com/owner/repo
        branch: str = "main",         # Branche cible
        target_dir: Path = None,      # RÃ©pertoire de clone
        depth: int = 1,               # Shallow clone (dÃ©faut: dernier commit)
    ) -> Path:
        """Clone un dÃ©pÃ´t GitHub (shallow par dÃ©faut)."""

    def filter_files(
        self,
        repo_path: Path,
        include_patterns: list[str],   # ["*.py", "*.md", "*.ts", "docs/**"]
        exclude_patterns: list[str],   # ["node_modules/**", "*.lock", ".git/**"]
        max_file_size_kb: int = 500,   # Ignorer les fichiers > 500 Ko
    ) -> list[Path]:
        """Filtre les fichiers pertinents du dÃ©pÃ´t."""

    def extract_repo_structure(
        self,
        repo_path: Path,
    ) -> str:
        """GÃ©nÃ¨re un arbre de la structure du dÃ©pÃ´t (format tree)."""

    def extract_repo_metadata(
        self,
        repo_url: str,
    ) -> dict:
        """Extrait les mÃ©tadonnÃ©es du dÃ©pÃ´t (description, langages, stars, topics)."""
```

#### 9.2.2 Patterns de filtrage par dÃ©faut

```yaml
# Profil "Code source" (dÃ©faut)
github_acquisition:
  include_patterns:
    - "*.py"
    - "*.js"
    - "*.ts"
    - "*.tsx"
    - "*.jsx"
    - "*.java"
    - "*.go"
    - "*.rs"
    - "*.c"
    - "*.cpp"
    - "*.h"
    - "*.rb"
    - "*.php"
    - "*.swift"
    - "*.kt"
    - "*.md"
    - "*.rst"
    - "*.txt"
    - "*.yaml"
    - "*.yml"
    - "*.json"
    - "*.toml"
    - "Dockerfile"
    - "Makefile"
    - "*.sh"
  exclude_patterns:
    - ".git/**"
    - "node_modules/**"
    - "vendor/**"
    - "__pycache__/**"
    - "*.pyc"
    - "*.min.js"
    - "*.min.css"
    - "*.lock"
    - "*.sum"
    - "dist/**"
    - "build/**"
    - ".next/**"
    - "*.map"
    - "*.wasm"
    - "*.bin"
    - "*.png"
    - "*.jpg"
    - "*.gif"
    - "*.svg"
    - "*.ico"
    - "*.woff"
    - "*.woff2"
    - "*.ttf"
    - "*.eot"
  max_file_size_kb: 500
  shallow_clone: true
  depth: 1
```

#### 9.2.3 Transformation en corpus

Chaque fichier du dÃ©pÃ´t est transformÃ© en document corpus avec :

```python
@dataclass
class RepoDocument:
    """Document extrait d'un dÃ©pÃ´t GitHub."""
    filepath: str              # Chemin relatif dans le repo
    content: str               # Contenu du fichier
    language: str              # Langage dÃ©tectÃ©
    file_type: str             # "code" | "documentation" | "config" | "test"
    line_count: int
    token_count: int
    repo_url: str
    branch: str
    last_modified: str         # Date du dernier commit sur ce fichier

    def to_corpus_entry(self) -> dict:
        """Convertit en entrÃ©e de corpus standard."""
        return {
            "text": self._format_for_corpus(),
            "source_file": f"github:{self.repo_url}#{self.filepath}",
            "metadata": {
                "doc_type": self.file_type,
                "language": self.language,
                "filepath": self.filepath,
                "line_count": self.line_count,
            }
        }

    def _format_for_corpus(self) -> str:
        """Formate le fichier pour l'injection dans le pipeline RAG."""
        header = f"# Fichier : {self.filepath}\n"
        header += f"# Langage : {self.language}\n"
        header += f"# Type : {self.file_type}\n\n"
        return header + self.content
```

#### 9.2.4 Chunking spÃ©cifique au code

Le `SemanticChunker` doit Ãªtre Ã©tendu pour le code source :

| StratÃ©gie | Application | Description |
|---|---|---|
| **Par classe/fonction** | Python, JavaScript, Java, Go | Une classe ou fonction = un chunk |
| **Par bloc logique** | Fichiers de config (YAML, JSON) | Un bloc de config = un chunk |
| **Par section** | Markdown, RST | Un titre = un chunk |
| **Par taille** | Fichiers longs | Fallback au chunking fixe |

```python
class CodeChunker:
    """Chunking sÃ©mantique spÃ©cifique au code source."""

    def chunk_python(self, content: str, filepath: str) -> list[CodeChunk]:
        """DÃ©coupe un fichier Python par classe/fonction."""

    def chunk_javascript(self, content: str, filepath: str) -> list[CodeChunk]:
        """DÃ©coupe un fichier JS/TS par export/function/class."""

    def chunk_generic(self, content: str, filepath: str) -> list[CodeChunk]:
        """Fallback : dÃ©coupage par blocs de lignes."""
```

### 9.3 Interface utilisateur

#### 9.3.1 Modifications de `page_acquisition.py`

Ajout d'un onglet "GitHub" dans la page d'acquisition :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“ Fichiers  |  ğŸŒ URLs  |  ğŸ™ GitHub                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  URL du dÃ©pÃ´t : [https://github.com/owner/repo         ]    â”‚
â”‚  Branche :      [main                                   ]    â”‚
â”‚                                                              â”‚
â”‚  â˜‘ Code source (*.py, *.js, *.ts, ...)                      â”‚
â”‚  â˜‘ Documentation (*.md, *.rst, README)                      â”‚
â”‚  â˜ Configuration (*.yaml, *.json, Dockerfile)               â”‚
â”‚  â˜ Tests (test_*, *_test.*)                                 â”‚
â”‚                                                              â”‚
â”‚  Taille max par fichier : [500] Ko                          â”‚
â”‚                                                              â”‚
â”‚  [ğŸ” Analyser le dÃ©pÃ´t]  [ğŸ“¥ Cloner et indexer]             â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€ AperÃ§u du dÃ©pÃ´t â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ“Š 142 fichiers, 38 500 lignes, ~96K tokens           â”‚  â”‚
â”‚  â”‚ ğŸ—‚ï¸ Langages : Python (65%), TypeScript (25%), MD (10%)â”‚  â”‚
â”‚  â”‚ ğŸ“ README.md dÃ©tectÃ©                                  â”‚  â”‚
â”‚  â”‚ ğŸ“‹ CHANGELOG.md dÃ©tectÃ©                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  Fichiers sÃ©lectionnÃ©s : 87/142 (~64K tokens)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â˜‘ src/main.py (245 lignes, Python)                    â”‚  â”‚
â”‚  â”‚ â˜‘ src/utils/helpers.py (120 lignes, Python)           â”‚  â”‚
â”‚  â”‚ â˜‘ README.md (180 lignes, Markdown)                    â”‚  â”‚
â”‚  â”‚ â˜ tests/test_main.py (90 lignes, Python)              â”‚  â”‚
â”‚  â”‚ ...                                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 9.3.2 Workflow utilisateur

1. L'utilisateur colle l'URL du dÃ©pÃ´t GitHub
2. **Analyser** : clone shallow, affiche la structure et les stats
3. L'utilisateur sÃ©lectionne les catÃ©gories de fichiers Ã  inclure
4. **Cloner et indexer** : extrait le contenu, transforme en corpus, indexe dans ChromaDB
5. Le corpus GitHub est fusionnÃ© avec les autres sources (fichiers, URLs) dans le pipeline RAG

### 9.4 IntÃ©gration avec le pipeline existant

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub   â”‚â”€â”€â”€â”€â–¶â”‚ GitHubAcq.   â”‚â”€â”€â”€â”€â–¶â”‚ CodeChunker  â”‚â”€â”€â”€â”€â–¶â”‚ RAGEngineâ”‚
â”‚ URL      â”‚     â”‚ clone+filter â”‚     â”‚ par langage  â”‚     â”‚ ChromaDB â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                     â”‚
                       â–¼                     â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Metadata â”‚         â”‚ SemanticChunk â”‚
                 â”‚ Store    â”‚         â”‚ (fallback)    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.5 DÃ©pendances

```
# Aucune dÃ©pendance supplÃ©mentaire requise
# git est utilisÃ© via subprocess (prÃ©sent sur tous les systÃ¨mes)
# L'API GitHub (optionnelle) est accessible via requests (dÃ©jÃ  en dÃ©pendance)
```

### 9.6 Configuration

Ajout dans `config/default.yaml` :

```yaml
# Phase 6 â€” Acquisition GitHub
github_acquisition:
  enabled: true
  shallow_clone: true
  depth: 1
  max_file_size_kb: 500
  max_total_files: 500           # Limite de fichiers par dÃ©pÃ´t
  max_total_tokens: 500000       # Limite de tokens par dÃ©pÃ´t
  cleanup_after_indexing: true   # Supprimer le clone aprÃ¨s indexation
  include_repo_structure: true   # Inclure l'arbre du dÃ©pÃ´t comme document
  include_patterns:
    - "*.py"
    - "*.js"
    - "*.ts"
    - "*.md"
    # ... (liste complÃ¨te dans le profil)
  exclude_patterns:
    - ".git/**"
    - "node_modules/**"
    # ... (liste complÃ¨te dans le profil)
```

### 9.7 Gestion des erreurs

| Erreur | Handling |
|---|---|
| DÃ©pÃ´t privÃ© sans token | Message clair : "DÃ©pÃ´t privÃ© â€” configurez `GITHUB_TOKEN` dans `.env`" |
| DÃ©pÃ´t trop volumineux (>1 Go) | Shallow clone obligatoire, avertissement sur le temps de clone |
| Timeout de clone | Timeout configurable (60s), retry 1x |
| Fichier binaire dans les patterns | DÃ©tection automatique (magic bytes), skip avec log |
| Encodage non-UTF8 | Tentative de dÃ©tection d'encodage, fallback latin-1 |

### 9.8 Livrables Phase 6

| # | Livrable | Fichier(s) |
|---|---|---|
| 6.1 | Module d'acquisition GitHub | `core/github_acquirer.py` (nouveau) |
| 6.2 | Chunking spÃ©cifique au code | `core/code_chunker.py` (nouveau) |
| 6.3 | Configuration GitHub | `config/default.yaml` (mise Ã  jour) |
| 6.4 | UI onglet GitHub | `pages/page_acquisition.py` (mise Ã  jour) |
| 6.5 | MÃ©tadonnÃ©es dÃ©pÃ´t | `core/metadata_store.py` (mise Ã  jour) |
| 6.6 | Profil "Documentation technique" | `profiles/default/documentation_technique.yaml` (nouveau) |
| 6.7 | Tests unitaires | `tests/unit/test_github_acquirer.py` |
| 6.8 | Tests d'intÃ©gration | `tests/integration/test_github_pipeline.py` |

---

## 10. Phase 7 â€” Orchestration multi-agents ğŸ“‹

> **Statut** : PlanifiÃ©
> **Objectif** : Pipeline agentic oÃ¹ plusieurs agents IA collaborent de maniÃ¨re autonome
> **PrioritÃ©** : Moyenne (dÃ©pend de la Phase 5)

### 10.1 Contexte

Actuellement, le pipeline est sÃ©quentiel : chaque section est gÃ©nÃ©rÃ©e une par une, avec Ã©valuation post-gÃ©nÃ©ration. L'orchestration multi-agents permettrait :
- Analyse parallÃ¨le du corpus par plusieurs agents spÃ©cialisÃ©s
- GÃ©nÃ©ration collaborative de sections interdÃ©pendantes
- VÃ©rification factuelle en temps rÃ©el pendant la gÃ©nÃ©ration
- Auto-correction itÃ©rative sans intervention humaine

### 10.2 Agents planifiÃ©s

| Agent | ModÃ¨le | RÃ´le |
|---|---|---|
| **Architecte** | Gemini 3.1 Pro (`high`) | Planification, structure, cohÃ©rence globale |
| **RÃ©dacteur** | Gemini 3.1 Pro (`medium`) | GÃ©nÃ©ration du contenu section par section |
| **VÃ©rificateur** | Gemini 3.1 Pro (`high`) | Factcheck, cohÃ©rence interne, sources |
| **Ã‰valuateur** | Gemini 3 Flash | Scoring qualitÃ© rapide, mÃ©triques |
| **Correcteur** | Gemini 3.1 Pro Custom Tools | Raffinement, intÃ©gration du feedback |

### 10.3 Flux multi-agents

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ARCHITECTE   â”‚
                    â”‚ (plan global) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼            â–¼            â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ RÃ‰DACTEUR  â”‚ â”‚ RÃ‰DACTEUR  â”‚ â”‚ RÃ‰DACTEUR  â”‚
       â”‚ Section 1  â”‚ â”‚ Section 2  â”‚ â”‚ Section 3  â”‚
       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
             â”‚              â”‚              â”‚
             â–¼              â–¼              â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚         VÃ‰RIFICATEUR (parallÃ¨le)       â”‚
       â”‚  factcheck + cohÃ©rence inter-sections  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Ã‰VALUATEUR  â”‚
                   â”‚ score final â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                    score < 3.0 ?
                     â–¼         â–¼
                   OUI        NON â†’ Export
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ CORRECTEUR  â”‚
              â”‚ raffinement â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.4 Utilisation du `gemini-3.1-pro-preview-customtools`

La variante Custom Tools est conÃ§ue pour les workflows oÃ¹ le modÃ¨le doit utiliser des outils personnalisÃ©s plutÃ´t que de tomber sur des commandes bash :

```python
tools = [
    types.Tool(function_declarations=[
        types.FunctionDeclaration(
            name="search_corpus",
            description="Recherche dans le corpus indexÃ©",
            parameters=types.Schema(
                type="OBJECT",
                properties={
                    "query": types.Schema(type="STRING"),
                    "top_k": types.Schema(type="INTEGER"),
                }
            )
        ),
        types.FunctionDeclaration(
            name="get_section_content",
            description="RÃ©cupÃ¨re le contenu d'une section dÃ©jÃ  gÃ©nÃ©rÃ©e",
            parameters=types.Schema(
                type="OBJECT",
                properties={
                    "section_id": types.Schema(type="STRING"),
                }
            )
        ),
        types.FunctionDeclaration(
            name="evaluate_quality",
            description="Ã‰value la qualitÃ© d'un contenu gÃ©nÃ©rÃ©",
            parameters=types.Schema(
                type="OBJECT",
                properties={
                    "content": types.Schema(type="STRING"),
                    "section_title": types.Schema(type="STRING"),
                }
            )
        ),
    ])
]
```

**Contrainte** : Les tools ne sont PAS compatibles avec `cached_content`. Le mode agentic et le mode cachÃ© sont mutuellement exclusifs. L'orchestrateur doit choisir :
- **Mode documentaire** : cache + gÃ©nÃ©ration rapide (Phase 5)
- **Mode agentic** : tools + raisonnement autonome (Phase 7)

### 10.5 Livrables Phase 7

| # | Livrable | Fichier(s) |
|---|---|---|
| 7.1 | Framework d'agents | `core/agent_framework.py` (nouveau) |
| 7.2 | Agent Architecte | `core/agents/architect_agent.py` (nouveau) |
| 7.3 | Agent RÃ©dacteur | `core/agents/writer_agent.py` (nouveau) |
| 7.4 | Agent VÃ©rificateur | `core/agents/verifier_agent.py` (nouveau) |
| 7.5 | Agent Ã‰valuateur | `core/agents/evaluator_agent.py` (nouveau) |
| 7.6 | Agent Correcteur | `core/agents/corrector_agent.py` (nouveau) |
| 7.7 | Orchestrateur multi-agents | `core/multi_agent_orchestrator.py` (nouveau) |
| 7.8 | Configuration mode agentic | `config/default.yaml` (mise Ã  jour) |
| 7.9 | UI mode agentic | `pages/page_generation.py` (mise Ã  jour) |
| 7.10 | Tests | `tests/integration/test_multi_agent.py` |

---

## 11. Matrice des dÃ©pendances

```
Phase 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Base
  â”‚
  â”œâ”€â”€ Phase 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Multi-providers
  â”‚     â”‚
  â”‚     â”œâ”€â”€ Phase 2.5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… RAG avancÃ©
  â”‚     â”‚     â”‚
  â”‚     â”‚     â”œâ”€â”€ Phase 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Intelligence
  â”‚     â”‚     â”‚     â”‚
  â”‚     â”‚     â”‚     â””â”€â”€ Phase 4 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Performance
  â”‚     â”‚     â”‚           â”‚
  â”‚     â”‚     â”‚           â”œâ”€â”€ Phase 5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Gemini 3.1 + Cache
  â”‚     â”‚     â”‚           â”‚     â”‚
  â”‚     â”‚     â”‚           â”‚     â””â”€â”€ Phase 7 â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“‹ Multi-agents
  â”‚     â”‚     â”‚           â”‚
  â”‚     â”‚     â”‚           â””â”€â”€ Phase 6 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ GitHub Acquisition
  â”‚     â”‚     â”‚
  â”‚     â”‚     â””â”€â”€ Phase 6 (aussi) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ (dÃ©pend de RAG)
```

| Phase | DÃ©pend de | Bloquant pour |
|---|---|---|
| Phase 5 | Phase 4 | Phase 7 |
| Phase 6 | Phase 2.5, Phase 4 | â€” |
| Phase 7 | Phase 5 | â€” |

**Phases 5 et 6 sont indÃ©pendantes** et peuvent Ãªtre dÃ©veloppÃ©es en parallÃ¨le.

---

## 12. Stack technique

### 12.1 DÃ©pendances (`requirements.txt`)

| CatÃ©gorie | Package | Version | Usage |
|---|---|---|---|
| **Interface** | streamlit | â‰¥1.30.0 | UI web |
| **AI Providers** | openai | â‰¥1.12.0 | API OpenAI |
| | anthropic | â‰¥0.39.0 | API Anthropic |
| | google-genai | â‰¥1.51.0 | API Gemini 3.1 (**minimum pour 3.x**) |
| **RAG** | chromadb | â‰¥0.5.0 | Base vectorielle |
| | fastembed | â‰¥0.2.0 | Embeddings ONNX |
| | sentence-transformers | â‰¥3.0 | Cross-encoder reranking |
| **PDF** | docling | â‰¥2.0 | Extraction structurÃ©e |
| | pymupdf | â‰¥1.23.0 | Fallback PDF |
| | pdfplumber | â‰¥0.10.0 | Fallback PDF |
| | PyPDF2 | â‰¥3.0.0 | Fallback PDF |
| **Documents** | python-docx | â‰¥1.1.0 | Import/export DOCX |
| | beautifulsoup4 | â‰¥4.12.0 | Parsing HTML |
| | openpyxl | â‰¥3.1.0 | Import Excel |
| | pandas | â‰¥2.1.0 | Traitement donnÃ©es |
| **Async** | aiohttp | â‰¥3.9.0 | TÃ©lÃ©chargement async |
| | aiofiles | â‰¥23.0.0 | I/O disque async |
| | psutil | â‰¥5.9.0 | Monitoring ressources |
| **Config** | pyyaml | â‰¥6.0.0 | Fichiers YAML |
| | python-dotenv | â‰¥1.0.0 | Variables d'environnement |
| **Tests** | pytest | â‰¥8.0.0 | Framework de test |
| | pytest-cov | â‰¥4.1.0 | Couverture de code |

### 12.2 Variables d'environnement (`.env`)

```bash
# Fournisseurs IA (au moins un requis)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AI...

# GitHub (optionnel, pour dÃ©pÃ´ts privÃ©s â€” Phase 6)
GITHUB_TOKEN=ghp_...
```

### 12.3 Infrastructure

| Composant | Technologie | HÃ©bergement |
|---|---|---|
| Application | Streamlit | Local / VM |
| Base vectorielle | ChromaDB (embedded) | Local (SQLite + HNSW) |
| MÃ©tadonnÃ©es | SQLite | Local |
| Embeddings | FastEmbed ONNX | Local (CPU, ~300 Mo) |
| Reranker | Cross-encoder | Local (CPU, ~100 Mo) |
| Cache AI | Gemini Context Cache | Google Cloud |
| GROBID | Docker (optionnel) | Local |

---

## 13. Annexes

### 13.1 Glossaire technique

| Terme | DÃ©finition |
|---|---|
| **RAG** | Retrieval-Augmented Generation â€” enrichit les prompts avec des donnÃ©es du corpus |
| **HITL** | Human-In-The-Loop â€” validation humaine Ã  des points de contrÃ´le |
| **Chunking** | DÃ©coupage du texte en blocs sÃ©mantiques pour la vectorisation |
| **Reranking** | Reclassement des rÃ©sultats de recherche par un modÃ¨le cross-encoder |
| **Context Caching** | Stockage cÃ´tÃ© serveur d'un prefix de prompt pour rÃ©utilisation |
| **Thinking Level** | ParamÃ¨tre Gemini 3.1 qui contrÃ´le la profondeur de raisonnement |
| **TTL** | Time-To-Live â€” durÃ©e de vie d'un cache avant expiration |
| **Shallow Clone** | Clone git limitÃ© au dernier commit (Ã©conomise bande passante) |

### 13.2 Patterns d'architecture utilisÃ©s

| Pattern | ImplÃ©mentation | Localisation |
|---|---|---|
| **Registry** | Enregistrement dynamique des providers | `utils/providers_registry.py` |
| **Factory** | Instanciation des providers par nom | `pages/page_configuration.py` |
| **Strategy** | ChaÃ®ne de fallback pour l'extraction PDF | `core/text_extractor.py` |
| **Observer** | Notifications de checkpoint HITL | `core/checkpoint_manager.py` |
| **Pipeline** | Flux asynchrone embedding // Ã©criture | `core/rag_engine.py` |
| **Cache** | LRU + disque pour extractions et recherches | `core/rag_engine.py`, `core/text_extractor.py` |
| **Chain of Resp.** | Fallback PDF (Docling â†’ PyMuPDF â†’ ...) | `core/text_extractor.py` |
| **Dataclass** | ModÃ¨les de donnÃ©es immuables | `core/orchestrator.py`, `providers/base.py` |

### 13.3 MÃ©triques de qualitÃ©

| CritÃ¨re | Poids | Seuil min | Auto-action |
|---|---|---|---|
| ConformitÃ© au plan | 1.0 | 2.0 | Raffinement |
| Couverture corpus | 1.5 | 2.0 | Raffinement |
| CohÃ©rence narrative | 0.8 | 2.0 | Raffinement |
| Taille cible | 0.5 | 1.5 | Raffinement |
| FiabilitÃ© factuelle | 1.5 | 2.5 | Factcheck + correction |
| TraÃ§abilitÃ© sources | 1.2 | 2.0 | Injection citations |

### 13.4 Estimation des coÃ»ts par scÃ©nario

#### ScÃ©nario A : Rapport 20 pages, corpus 50K tokens, 15 sections

| Provider | Sans cache | Avec cache (Gemini) | Ã‰conomie |
|---|---|---|---|
| GPT-4.1 | ~$3.50 | N/A | â€” |
| Claude Sonnet 4.5 | ~$4.20 | N/A | â€” |
| Gemini 3.1 Pro | ~$3.00 | ~$0.85 | **72%** |
| Gemini 3 Flash | ~$0.45 | ~$0.12 | **73%** |

#### ScÃ©nario B : Documentation technique 50 pages, dÃ©pÃ´t GitHub 200K tokens, 30 sections

| Provider | Sans cache | Avec cache (Gemini) | Ã‰conomie |
|---|---|---|---|
| GPT-4.1 | ~$14.00 | N/A | â€” |
| Gemini 3.1 Pro | ~$13.20 | ~$2.10 | **84%** |
| Gemini 3 Flash | ~$1.80 | ~$0.30 | **83%** |

*Note : les estimations incluent input, output, rÃ©sumÃ©s et Ã©valuation qualitÃ©. Le coÃ»t de stockage du cache (~$0.50/h pour 200K tokens) est inclus pour une session de 2h.*

### 13.5 Roadmap de livraison

| Phase | Estimation | DÃ©pendance |
|---|---|---|
| Phase 5 â€” Gemini 3.1 + Cache | â€” | Phase 4 âœ… |
| Phase 6 â€” GitHub Acquisition | â€” | Phase 2.5 âœ… |
| Phase 7 â€” Multi-agents | â€” | Phase 5 |

**Phases 5 et 6 peuvent Ãªtre dÃ©veloppÃ©es en parallÃ¨le.**

---

> *Document gÃ©nÃ©rÃ© pour le projet Orchestr'IA â€” FÃ©vrier 2026*
